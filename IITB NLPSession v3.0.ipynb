{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "##   Notebook used for extracting text from html files. Some basic preprocessing tasks \n",
    "##   v3.0 Unsupervised classification using gensim\n",
    "##   Required packages: os, logging, collections, gensim\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.12'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cross checking the python version that has been installed\n",
    "##\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importing the logging function which provides logs for debugging\n",
    "##\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Raw corpus used for training n unsupervised gensim model\n",
    "##\n",
    "raw_corpus = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of frequent words. Using only a rudimentary set of stop words\n",
    "# Kindly note in our use casse removing stop words may create problems\n",
    "stoplist = set('for a of the and to in'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in raw_corpus]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'abc': 1,\n",
       "             'applications': 1,\n",
       "             'binary': 1,\n",
       "             'computer': 2,\n",
       "             'engineering': 1,\n",
       "             'eps': 2,\n",
       "             'error': 1,\n",
       "             'generation': 1,\n",
       "             'graph': 3,\n",
       "             'human': 2,\n",
       "             'interface': 2,\n",
       "             'intersection': 1,\n",
       "             'iv': 1,\n",
       "             'lab': 1,\n",
       "             'machine': 1,\n",
       "             'management': 1,\n",
       "             'measurement': 1,\n",
       "             'minors': 2,\n",
       "             'opinion': 1,\n",
       "             'ordering': 1,\n",
       "             'paths': 1,\n",
       "             'perceived': 1,\n",
       "             'quasi': 1,\n",
       "             'random': 1,\n",
       "             'relation': 1,\n",
       "             'response': 2,\n",
       "             'survey': 2,\n",
       "             'system': 4,\n",
       "             'testing': 1,\n",
       "             'time': 2,\n",
       "             'trees': 3,\n",
       "             'unordered': 1,\n",
       "             'user': 3,\n",
       "             'well': 1,\n",
       "             'widths': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "processed_corpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Associate each word in the corpus with an unique integer ID. This will be a small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:843: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-01-23 13:17:47,016 : WARNING : Slow version of gensim.models.doc2vec is being used\n",
      "2017-01-23 13:17:47,048 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-01-23 13:17:47,055 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-01-23 13:17:47,055 : INFO : built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "2017-01-23 13:17:47,056 : INFO : saving Dictionary object under deerwester.dict, separately None\n",
      "2017-01-23 13:17:47,059 : INFO : saved deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)\n",
    "\n",
    "## Dictionary is stored to disk using save()\n",
    "dictionary.save('deerwester.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 11)\n",
      "(1, 10)\n",
      "(2, 6)\n",
      "(3, 9)\n",
      "(4, 8)\n",
      "(5, 1)\n",
      "(6, 5)\n",
      "(7, 7)\n",
      "(8, 2)\n",
      "(9, 4)\n",
      "(10, 0)\n",
      "(11, 3)\n"
     ]
    }
   ],
   "source": [
    "# Simply enumerating through the dictionary\n",
    "for i in enumerate(dictionary):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'minors': 11, u'graph': 10, u'system': 6, u'trees': 9, u'eps': 8, u'computer': 1, u'survey': 5, u'user': 7, u'human': 2, u'time': 4, u'interface': 0, u'response': 3}\n"
     ]
    }
   ],
   "source": [
    "# Better way to do the above\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the output with a new document\n",
    "##\n",
    "new_doc = 'Human computer interaction'\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:47,448 : INFO : storing corpus in Matrix Market format to deerwester.mm\n",
      "2017-01-23 13:17:47,450 : INFO : saving sparse matrix to deerwester.mm\n",
      "2017-01-23 13:17:47,451 : INFO : PROGRESS: saving document #0\n",
      "2017-01-23 13:17:47,453 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2017-01-23 13:17:47,454 : INFO : saving MmCorpus index to deerwester.mm.index\n"
     ]
    }
   ],
   "source": [
    "# Converting the entire corpus into a list of vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "bow_corpus\n",
    "# Mode persistency by serializing the list of vectors and storing to disk, for later use\n",
    "corpora.MmCorpus.serialize('deerwester.mm', bow_corpus)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In gensim documents are represented as vectors so a model can be thought of as a transformation between two vector spaces. The detail of this transformation is learned from the training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:48,246 : INFO : collecting document frequencies\n",
      "2017-01-23 13:17:48,246 : INFO : PROGRESS: processing document #0\n",
      "2017-01-23 13:17:48,247 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check the difference in the tfidf tuples. When we use minors vs minor.\n",
    "Note that minor is not present in the training data while, minors is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 0.5898341626740045), (11, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "#transform the \"system minors\" sting\n",
    "print tfidf[dictionary.doc2bow(\"system minors\".lower().split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "## Check what happens when we use 'minor'instead of 'minors'\n",
    "## this is a word which the model has not seen\n",
    "print tfidf[dictionary.doc2bow(\"system minor\".lower().split())]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note how the word 'minor' has been rejected by the model, and is not vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(1, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.44424552527467476), (6, 0.3244870206138555), (7, 0.3244870206138555)]\n",
      "[(0, 0.5710059809418182), (6, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(2, 0.49182558987264147), (6, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (4, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(5, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "## Running the entire corpus through a tfidf transformation\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:51,161 : INFO : loading Dictionary object from deerwester.dict\n",
      "2017-01-23 13:17:51,161 : INFO : loaded deerwester.dict\n",
      "2017-01-23 13:17:51,164 : INFO : loaded corpus index from deerwester.mm.index\n",
      "2017-01-23 13:17:51,164 : INFO : initializing corpus reader from deerwester.mm\n",
      "2017-01-23 13:17:51,165 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "## model persistency using save & load\n",
    "## \n",
    "dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    "corpus = corpora.MmCorpus('deerwester.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (1, 1.0), (2, 1.0)]\n",
      "[(1, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(0, 1.0), (6, 1.0), (7, 1.0), (8, 1.0)]\n",
      "[(2, 1.0), (6, 2.0), (8, 1.0)]\n",
      "[(3, 1.0), (4, 1.0), (7, 1.0)]\n",
      "[(9, 1.0)]\n",
      "[(9, 1.0), (10, 1.0)]\n",
      "[(9, 1.0), (10, 1.0), (11, 1.0)]\n",
      "[(5, 1.0), (10, 1.0), (11, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "corpus\n",
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'computer': 1,\n",
       " u'eps': 8,\n",
       " u'graph': 10,\n",
       " u'human': 2,\n",
       " u'interface': 0,\n",
       " u'minors': 11,\n",
       " u'response': 3,\n",
       " u'survey': 5,\n",
       " u'system': 6,\n",
       " u'time': 4,\n",
       " u'trees': 9,\n",
       " u'user': 7}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:52,940 : INFO : using serial LSI version on this node\n",
      "2017-01-23 13:17:52,940 : INFO : updating model with new documents\n",
      "2017-01-23 13:17:52,943 : INFO : preparing a new chunk of documents\n",
      "2017-01-23 13:17:52,944 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-01-23 13:17:52,944 : INFO : 1st phase: constructing (12L, 102L) action matrix\n",
      "2017-01-23 13:17:52,944 : INFO : orthonormalizing (12L, 102L) action matrix\n",
      "2017-01-23 13:17:52,948 : INFO : 2nd phase: running dense svd on (12L, 9L) matrix\n",
      "2017-01-23 13:17:52,950 : INFO : computing the final decomposition\n",
      "2017-01-23 13:17:52,951 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2017-01-23 13:17:52,953 : INFO : processed documents up to #9\n",
      "2017-01-23 13:17:52,953 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2017-01-23 13:17:52,953 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "## Run the corpus through a LSI (Latent Semantic Indexing) model. Model is run for 2 topics\n",
    "##\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:53,548 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2017-01-23 13:17:53,549 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"'),\n",
       " (1,\n",
       "  u'-0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print out the topics \n",
    "##\n",
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.38074310701391734), (1, 0.082050389870936852)]\n",
      "[(0, 0.7738776922717463), (1, -0.20017851856109192)]\n",
      "[(0, 0.72176013142126449), (1, 0.16780348860319411)]\n",
      "[(0, 0.71986853282732621), (1, 0.24534782790425577)]\n",
      "[(0, 0.51823292135519583), (1, -0.16083692447760997)]\n",
      "[(0, 0.012746183038294404), (1, -0.4901617924531036)]\n",
      "[(0, 0.034564816348136761), (1, -0.78697238988812523)]\n",
      "[(0, 0.046922170256372159), (1, -0.8787747019489105)]\n",
      "[(0, 0.16590324484677316), (1, -0.74074942773116415)]\n"
     ]
    }
   ],
   "source": [
    "## Run the entire corpus through the lsi model \n",
    "##\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "for doc in corpus_lsi:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271568), (1, 0.070027665278999535)]\n"
     ]
    }
   ],
   "source": [
    "## Convert a new document to a bag of words and then run through the lsi model\n",
    "## \n",
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:55,573 : INFO : saving Projection object under model.lsi.projection, separately None\n",
      "2017-01-23 13:17:55,578 : INFO : saved model.lsi.projection\n",
      "2017-01-23 13:17:55,579 : INFO : saving LsiModel object under model.lsi, separately None\n",
      "2017-01-23 13:17:55,581 : INFO : not storing attribute projection\n",
      "2017-01-23 13:17:55,582 : INFO : not storing attribute dispatcher\n",
      "2017-01-23 13:17:55,585 : INFO : saved model.lsi\n",
      "2017-01-23 13:17:55,585 : INFO : loading LsiModel object from model.lsi\n",
      "2017-01-23 13:17:55,586 : INFO : loading id2word recursively from model.lsi.id2word.* with mmap=None\n",
      "2017-01-23 13:17:55,588 : INFO : setting ignored attribute projection to None\n",
      "2017-01-23 13:17:55,588 : INFO : setting ignored attribute dispatcher to None\n",
      "2017-01-23 13:17:55,589 : INFO : loaded model.lsi\n",
      "2017-01-23 13:17:55,591 : INFO : loading LsiModel object from model.lsi.projection\n",
      "2017-01-23 13:17:55,592 : INFO : loaded model.lsi.projection\n"
     ]
    }
   ],
   "source": [
    "## Again for model persistency store the model to disk\n",
    "lsi.save('model.lsi') # same for tfidf, lda, ...\n",
    "lsi = models.LsiModel.load('model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:56,118 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-01-23 13:17:56,119 : INFO : creating matrix with 9 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "# transform corpus to LSI space and index it\n",
    "\n",
    "index = similarities.MatrixSimilarity(lsi[corpus]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 13:17:56,601 : INFO : saving MatrixSimilarity object under deerwester.index, separately None\n",
      "2017-01-23 13:17:56,604 : INFO : saved deerwester.index\n",
      "2017-01-23 13:17:56,605 : INFO : loading MatrixSimilarity object from deerwester.index\n",
      "2017-01-23 13:17:56,607 : INFO : loaded deerwester.index\n"
     ]
    }
   ],
   "source": [
    "## Save and load \n",
    "index.save('deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('deerwester.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sims = index[vec_lsi] # perform a similarity query against the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99809301), (1, 0.93748635), (2, 0.99844527), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.098794639), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(sims))) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.99844527), (0, 0.99809301), (3, 0.9865886), (1, 0.93748635), (4, 0.90755945), (8, 0.050041765), (7, -0.098794639), (6, -0.10639259), (5, -0.12416792)]\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims) # print sorted (document number, similarity score) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_corpus = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.99844527) The EPS user interface management system\n",
      "(0, 0.99809301) Human machine interface for lab abc computer applications\n",
      "(3, 0.9865886) System and human system engineering testing of EPS\n",
      "(1, 0.93748635) A survey of user opinion of computer system response time\n",
      "(4, 0.90755945) Relation of user perceived response time to error measurement\n",
      "(8, 0.050041765) Graph minors A survey\n",
      "(7, -0.098794639) Graph minors IV Widths of trees and well quasi ordering\n",
      "(6, -0.10639259) The intersection graph of paths in trees\n",
      "(5, -0.12416792) The generation of random binary unordered trees\n"
     ]
    }
   ],
   "source": [
    "for _, cos in enumerate(sims):\n",
    "    print cos, raw_corpus[cos[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
